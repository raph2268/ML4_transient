{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f830ca0-b5f3-4674-bfba-13112e23a4db",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941c615b-eeff-43fb-9111-775ff4c5af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.cifar import CIFAR10, CIFAR100\n",
    "from data.bogus_transient import create_dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85bf8f1-09f6-42e9-bbde-bfc01d4bb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from model import CNN, CustomCNN\n",
    "import argparse, sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from loss import loss_coteaching_binary\n",
    "from df_bogus import df_proba_pytorch, spy\n",
    "from Retrieve_data import retrieve_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbea960-1f23-44ea-b5c5-6e68ca21d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "epoch_decay_start = 80\n",
    "exponent = 1\n",
    "num_gradual = 10\n",
    "forget_rate = 0.2\n",
    "num_iter_per_epoch = 400\n",
    "print_freq =50\n",
    "\n",
    "result_dir = 'results'\n",
    "dataset = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cfb00-6005-42d8-9fb6-652b580bc861",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8698ade-d1d9-4b46-a721-f4ad6e43030b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "visits = [95092, 91556, 101500, 104516]\n",
    "visit =90780\n",
    "train_dataset = create_dataset(visit, train=True)\n",
    "test_dataset = create_dataset(visit, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed8f320-ff47-4091-a0bb-04e2f5b2b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b870dc-4676-4bcf-ae0d-8967c676dde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, target, idx = train_dataset[14]\n",
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a638c46-8dcb-483c-ae37-bede901030c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([128, 1, 30, 30])\n",
      "Labels shape: torch.Size([128])\n",
      "Labels shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels, idx = next(data_iter)\n",
    "\n",
    "# Print the shapes\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Labels shape: {idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e8a632-9544-4e34-9bad-ed0ca60af793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_dataset = CIFAR100(root='./data/',\\n                                download=True,  \\n                                train=False, \\n                            )\\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\\n                                           batch_size=batch_size, \\n                                           drop_last=True,\\n                                           shuffle=True)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_dataset = CIFAR100(root='./data/',\n",
    "                                download=True,  \n",
    "                                train=False, \n",
    "                            )\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           drop_last=True,\n",
    "                                           shuffle=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c298f02-e8ce-46b8-839b-feb9489328de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, target, index = train_dataset[9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3f257-269e-40c4-b417-57a2c4c11a08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Prepare Co-teaching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c5db6ca-13fe-497d-aa25-fa0f407e3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust learning rate and betas for Adam Optimizer\n",
    "mom1 = 0.9\n",
    "mom2 = 0.1\n",
    "alpha_plan = [learning_rate] * epochs\n",
    "beta1_plan = [mom1] * epochs\n",
    "for i in range(epoch_decay_start, epochs):\n",
    "    alpha_plan[i] = float(epochs - i) / (epochs - epoch_decay_start) * learning_rate\n",
    "    beta1_plan[i] = mom2\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=alpha_plan[epoch]\n",
    "        param_group['betas']=(beta1_plan[epoch], 0.999) # Only change beta1\n",
    "        \n",
    "# define drop rate schedule\n",
    "rate_schedule = np.ones(epochs)*forget_rate\n",
    "rate_schedule[:num_gradual] = np.linspace(0, forget_rate**exponent, num_gradual)\n",
    "   \n",
    "save_dir ='results/co_teaching_test1'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.system('mkdir -p %s' % save_dir)\n",
    "\n",
    "model_str='co_teaching_test1'\n",
    "\n",
    "txtfile=save_dir+\"/\"+model_str+\".txt\"\n",
    "nowTime=datetime.datetime.now().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "if os.path.exists(txtfile):\n",
    "    os.system('mv %s %s' % (txtfile, txtfile+\".bak-%s\" % nowTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4798f728-88b9-4bb3-93d9-88e78792524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logit, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    output = torch.sigmoid(logit)\n",
    "    batch_size = target.size(0)\n",
    "    pred = (output > 0.5).long()\n",
    "    correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4462df93-38f1-42ad-b73a-a64ca73ff29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "def train(train_loader, epoch, model1, optimizer1, model2, optimizer2):\n",
    "    print(f'Training {model_str}...')\n",
    "    pure_ratio_list = []\n",
    "    pure_ratio_1_list = []\n",
    "    pure_ratio_2_list = []\n",
    "    \n",
    "    train_total1 = 0\n",
    "    train_correct1 = 0 \n",
    "    train_total2 = 0\n",
    "    train_correct2 = 0 \n",
    "\n",
    "    for i, (images, labels, idx) in enumerate(train_loader):\n",
    "        ind=idx.cpu().numpy().transpose()\n",
    "        if i > num_iter_per_epoch:\n",
    "            break\n",
    "        \n",
    "        images = images\n",
    "        labels = labels\n",
    "        # Ensure labels are float for binary classification\n",
    "        \n",
    "        # Forward Pass for Model 1\n",
    "        logits1 = model1(images)\n",
    "        prec1 = accuracy(logits1, labels, topk=(1,))  # Update accuracy calculation for binary\n",
    "        train_total1 += len(labels)\n",
    "        train_correct1 += prec1[0].item()  # Ensure it's a number\n",
    "\n",
    "        # Forward Pass for Model 2\n",
    "        logits2 = model2(images)\n",
    "        prec2 = accuracy(logits2, labels, topk=(1,))  # Update accuracy calculation for binary\n",
    "        train_total2 += len(labels)\n",
    "        train_correct2 += prec2[0].item()  # Ensure it's a number\n",
    "        \n",
    "        # Compute Co-Teaching Loss\n",
    "        loss_1, loss_2 = loss_coteaching_binary(\n",
    "            logits1, logits2, labels, rate_schedule[epoch], ind)#, noise_or_not\n",
    "        \"\"\")\n",
    "        pure_ratio_1_list.append(100 * pure_ratio_1)\n",
    "        pure_ratio_2_list.append(100 * pure_ratio_2)\n",
    "        \"\"\"\n",
    "        # Backward and Optimize\n",
    "        optimizer1.zero_grad()\n",
    "        loss_1.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        optimizer2.zero_grad()\n",
    "        loss_2.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        # Print log info\n",
    "        if (i + 1) % print_freq == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch+1}/{epochs}], Iter [{i+1}/{len(train_loader)}] '\n",
    "                f'Training Accuracy1: {prec1[0].item()}, Training Accuracy2: {prec2[0].item()}, '\n",
    "                f'Loss1: {loss_1.item()}, Loss2: {loss_2.item()}, ')\n",
    "                \n",
    "            \"\"\"f'Pure Ratio1: {np.sum(pure_ratio_1_list) / len(pure_ratio_1_list):.4f}, '\n",
    "                f'Pure Ratio2: {np.sum(pure_ratio_2_list) / len(pure_ratio_2_list):.4f}'\n",
    "            )\"\"\"\n",
    "\n",
    "    train_acc1 = float(train_correct1) / float(train_total1)\n",
    "    train_acc2 = float(train_correct2) / float(train_total2)\n",
    "    return train_acc1, train_acc2\n",
    "\n",
    "#, pure_ratio_1_list, pure_ratio_2_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4d590f-7121-45c2-9517-2169e9cada3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d607d330-77a7-4b57-b1ce-9ebcc9052a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Evaluate the Model\n",
    "def evaluate(test_loader, model1, model2):\n",
    "    print('Evaluating %s...' % model_str)\n",
    "    \n",
    "    # Set models to evaluation mode\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    \n",
    "    correct1 = 0\n",
    "    total1 = 0\n",
    "    correct2 = 0\n",
    "    total2 = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for images, labels, _ in test_loader:\n",
    "            # Remove .cuda() if not using GPU\n",
    "            images = images  # images = images.cuda() if using GPU\n",
    "            labels = labels  # labels = labels.cuda() if using GPU\n",
    "            # Model 1 evaluation\n",
    "            logits1 = model1(images)\n",
    "            probs1 = torch.sigmoid(logits1)  # Use sigmoid for binary classification\n",
    "            pred1 = (probs1 > 0.5).float() \n",
    "            #pred1 = torch.argmax(probs1, dim=1)# Apply threshold to get binary predictions\n",
    "\n",
    "            total1 += labels.size(0)\n",
    "            correct1 += (pred1.squeeze() == labels).sum().item()  # Convert tensor to scalar\n",
    "            \n",
    "            # Model 2 evaluation\n",
    "            logits2 = model2(images)\n",
    "            probs2 = torch.sigmoid(logits2)  # Use sigmoid for binary classification\n",
    "            pred2 = (probs2 > 0.5).float()  # Apply threshold to get binary predictions\n",
    "\n",
    "            total2 += labels.size(0)\n",
    "            correct2 += (pred2.squeeze() == labels).sum().item()  # Convert tensor to scalar\n",
    "\n",
    "    # Calculate accuracies\n",
    "    acc1 = 100 * correct1 / total1\n",
    "    acc2 = 100 * correct2 / total2\n",
    "    return acc1, acc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565ba33c-1fc6-4b72-ae1f-b7dc53b5c16b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "<bound method Module.parameters of CNN(\n",
      "  (c1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c8): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (l_c1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")>\n",
      "<bound method Module.parameters of CNN(\n",
      "  (c1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c8): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (l_c1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_channel = 1\n",
    "num_classes = 1\n",
    "# Define models\n",
    "print('building model...')\n",
    "cnn1 = CNN(input_channel=input_channel, n_outputs=num_classes)\n",
    "cnn1\n",
    "\n",
    "\n",
    "print(cnn1.parameters)\n",
    "optimizer1 = torch.optim.Adam(cnn1.parameters(), lr=learning_rate)\n",
    "\n",
    "cnn2 = CNN(input_channel=input_channel, n_outputs=num_classes)\n",
    "cnn2\n",
    "print(cnn2.parameters)\n",
    "optimizer2 = torch.optim.Adam(cnn2.parameters(), lr=learning_rate)\n",
    "\n",
    "mean_pure_ratio1=0\n",
    "mean_pure_ratio2=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ed7a3-4f2f-4223-be7f-d0a0c47fca60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Launch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e56fb1e0-c9c5-4731-bdee-3b9ebd029ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating co_teaching_test1...\n",
      "Epoch [201/200] Test Accuracy on the 10673 test images: Model1 65.6610 % Model2 65.6610 % Pure Ratio1 0.0000 % Pure Ratio2 0.0000 %\n"
     ]
    }
   ],
   "source": [
    "with open(txtfile, \"a\") as myfile:\n",
    "    myfile.write('epoch: train_acc1 train_acc2 test_acc1 test_acc2 pure_ratio1 pure_ratio2\\n')\n",
    "\n",
    "epoch=0\n",
    "train_acc1=0\n",
    "train_acc2=0\n",
    "# evaluate models with random weights\n",
    "test_acc1, test_acc2=evaluate(test_loader, cnn1, cnn2)\n",
    "\n",
    "print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %% Pure Ratio1 %.4f %% Pure Ratio2 %.4f %%' % (epochs+1, epochs, len(test_dataset), test_acc1, test_acc2, mean_pure_ratio1, mean_pure_ratio2))\n",
    "# save results\n",
    "with open(txtfile, \"a\") as myfile:\n",
    "    myfile.write(str(int(epoch)) + ': '  + str(train_acc1) +' '  + str(train_acc2) +' '  + str(test_acc1) + \" \" + str(test_acc2) + ' '  + str(mean_pure_ratio1) + ' '  + str(mean_pure_ratio2) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fef4664-7554-4cf5-a69e-05b4f59cb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (30, 30, 1)\n",
    "NUM_CLASSES = 2\n",
    "filters_1 = 32\n",
    "filters_2 = 64\n",
    "dropout_1 = 0.25\n",
    "dropout_2 = 0.25\n",
    "dropout_3 = 0.5\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "830b7d69-aa6a-4729-856b-acaf6343909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes, filters_1, dropout_1, filters_2, dropout_2, units, dropout_3):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_shape[2], out_channels=filters_1, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout1 = nn.Dropout(dropout_1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=filters_1, out_channels=filters_2, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout2 = nn.Dropout(dropout_2)\n",
    "        self.fc1 = nn.Linear(in_features=filters_2 * (input_shape[0] // 4) * (input_shape[1] // 4), out_features=units)\n",
    "        self.dropout3 = nn.Dropout(dropout_3)\n",
    "        self.fc2 = nn.Linear(in_features=units, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe71fef2-ea38-4e4e-9072-c7602a40e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    filters_1=filters_1,\n",
    "    dropout_1=dropout_1,\n",
    "    filters_2=filters_2,\n",
    "    dropout_2=dropout_2,\n",
    "    units=units,\n",
    "    dropout_3=dropout_3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39a812b9-1250-4053-8750-24e763420fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2651, Accuracy: 0.8874\n",
      "Epoch [2/10], Loss: 0.2047, Accuracy: 0.9202\n",
      "Epoch [3/10], Loss: 0.1919, Accuracy: 0.9261\n",
      "Epoch [4/10], Loss: 0.1851, Accuracy: 0.9290\n",
      "Epoch [5/10], Loss: 0.1810, Accuracy: 0.9308\n",
      "Epoch [6/10], Loss: 0.1771, Accuracy: 0.9323\n",
      "Epoch [7/10], Loss: 0.1750, Accuracy: 0.9332\n",
      "Epoch [8/10], Loss: 0.1731, Accuracy: 0.9337\n",
      "Epoch [9/10], Loss: 0.1709, Accuracy: 0.9349\n",
      "Epoch [10/10], Loss: 0.1694, Accuracy: 0.9355\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Assuming you have already defined your model, criterion, optimizer, etc.\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels, _ in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs).squeeze()  # Forward pass, remove singleton dimensions if necessary\n",
    "        loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate predictions\n",
    "        preds = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "        predicted_classes = (preds >= 0.5).float()  # Convert probabilities to binary predictions (0 or 1)\n",
    "\n",
    "        # Update total and correct counts\n",
    "        total += labels.size(0)  # Increase total count\n",
    "        correct += (predicted_classes == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "    # Calculate and print loss and accuracy\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b603c50c-9386-4e1d-8bfb-561a7bb4a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1688, Train Accuracy: 0.9364, Val Loss: 0.1494, Val Accuracy: 0.9444\n",
      "Epoch [2/10], Train Loss: 0.1663, Train Accuracy: 0.9371, Val Loss: 0.1523, Val Accuracy: 0.9433\n",
      "Epoch [3/10], Train Loss: 0.1644, Train Accuracy: 0.9373, Val Loss: 0.1514, Val Accuracy: 0.9427\n",
      "Epoch [4/10], Train Loss: 0.1647, Train Accuracy: 0.9376, Val Loss: 0.1508, Val Accuracy: 0.9426\n",
      "Epoch [5/10], Train Loss: 0.1634, Train Accuracy: 0.9379, Val Loss: 0.1511, Val Accuracy: 0.9424\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Training Loop\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels, _ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Remove singleton dimensions\u001b[39;00m\n",
      "File \u001b[0;32m/pbs/software/centos-7-x86_64/anaconda/3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/pbs/software/centos-7-x86_64/anaconda/3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/pbs/software/centos-7-x86_64/anaconda/3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/pbs/software/centos-7-x86_64/anaconda/3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/sps/lsst/users/rbonnetguerrini/ML4_transientV2/co_teaching/data/bogus_transient.py:37\u001b[0m, in \u001b[0;36mcreate_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Convert image to a PyTorch tensor\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Remove the channel dimension\u001b[39;00m\n\u001b[1;32m     38\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Example code with added accuracy tracking\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    for inputs, labels, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()  # Remove singleton dimensions\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        predicted = torch.sigmoid(outputs) > 0.5  # Convert logits to binary predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Training loss and accuracy\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels, _ in test_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03e262b1-8cea-47df-bdc8-1a0d16983bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9394\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    for inputs, labels, _ in test_loader:\n",
    "        outputs = model(inputs).squeeze()  # Get raw logits\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert probabilities to binary predictions using a threshold of 0.5\n",
    "        predicted = probabilities > 0.5\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09799209-0eec-4da5-b2d0-a1effdfd20a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training co_teaching_test1...\n",
      "Epoch [2/200], Iter [50/334] Training Accuracy1: 0.78125, Training Accuracy2: 0.78125, Loss1: 0.20190900564193726, Loss2: 0.17893506586551666, \n",
      "Epoch [2/200], Iter [100/334] Training Accuracy1: 0.0, Training Accuracy2: 0.0, Loss1: 0.20955690741539001, Loss2: 0.19381868839263916, \n",
      "Epoch [2/200], Iter [150/334] Training Accuracy1: 0.78125, Training Accuracy2: 0.78125, Loss1: 0.12380366027355194, Loss2: 0.14224568009376526, \n",
      "Epoch [2/200], Iter [200/334] Training Accuracy1: 0.78125, Training Accuracy2: 0.78125, Loss1: 0.09180725365877151, Loss2: 0.10487257689237595, \n",
      "Epoch [2/200], Iter [250/334] Training Accuracy1: 0.0, Training Accuracy2: 0.0, Loss1: 0.1417517215013504, Loss2: 0.12223520129919052, \n",
      "Epoch [2/200], Iter [300/334] Training Accuracy1: 0.78125, Training Accuracy2: 0.78125, Loss1: 0.10859791934490204, Loss2: 0.10563334822654724, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m cnn2\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m adjust_learning_rate(optimizer2, epoch)\n\u001b[0;32m----> 8\u001b[0m train_acc1, train_acc2\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, epoch, model1, optimizer1, model2, optimizer2)\u001b[0m\n\u001b[1;32m     29\u001b[0m prec2 \u001b[38;5;241m=\u001b[39m accuracy(logits2, labels, topk\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,))  \u001b[38;5;66;03m# Update accuracy calculation for binary\u001b[39;00m\n\u001b[1;32m     30\u001b[0m train_total2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[0;32m---> 31\u001b[0m train_correct2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mprec2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure it's a number\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Compute Co-Teaching Loss\u001b[39;00m\n\u001b[1;32m     34\u001b[0m loss_1, loss_2 \u001b[38;5;241m=\u001b[39m loss_coteaching_binary(\n\u001b[1;32m     35\u001b[0m     logits1, logits2, labels, rate_schedule[epoch], ind)\u001b[38;5;66;03m#, noise_or_not\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(0, 5):\n",
    "    # train models\n",
    "    cnn1.train()\n",
    "    adjust_learning_rate(optimizer1, epoch)\n",
    "    cnn2.train()\n",
    "    adjust_learning_rate(optimizer2, epoch)\n",
    "    train_acc1, train_acc2=train(train_loader, epoch, cnn1, optimizer1, cnn2, optimizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f3856-2b70-446e-b85e-15e6ae41bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models\n",
    "test_acc1, test_acc2=evaluate(test_loader, cnn1, cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f558d-7838-4f10-99f0-029a312d654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn1.state_dict(), 'cnn1_model.pth')\n",
    "torch.save(cnn2.state_dict(), 'cnn2_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975797ab-88c6-4ad9-8bdf-7df84aa7d17a",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4add0c40-00a3-4653-a330-96f328f6a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (c1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (c8): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (c9): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (l_c1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(input_channel=1, n_outputs=1)\n",
    "\n",
    "model.load_state_dict(torch.load('cnn1_model.pth'))\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7ad0881-4d28-440e-bb73-a85709fe56de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    for inputs, labels, _ in test_loader:\n",
    "        outputs = model(inputs).squeeze()  # Get raw logits\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        # Convert probabilities to binary predictions using a threshold of 0.5\n",
    "        predicted = probabilities > 0.5\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f062505-0ff8-4296-a898-6509f9d18dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from Retrieve_data import retrieve_data\n",
    "data = retrieve_data(nbre_visit=visit)\n",
    "df_train, df_test, x_train, x_test, y_train, y_test = data.donnees(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c53c4-569e-4beb-af9e-677bb9c26a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [np.transpose(i, (2, 0, 1)) for i in x_test]\n",
    "\n",
    "x_test_tensor = torch.tensor(np.array(X_test), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test,  dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece8d3e-f706-4c8f-aa7d-1a52f3221ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    outputs = model(x_test_tensor).squeeze()  # Get raw logits\n",
    "    probabilities = torch.sigmoid(outputs).numpy()  # Apply sigmoid to get probabilities\n",
    "\n",
    "\n",
    "df_test['proba_transient'] = probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caef9e45-6f7b-4ea5-baa3-8a0ebd5b32b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx_transient = df_test[f'proba_transient'].loc[df_test['y_test'] == 1]\n",
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "\n",
    "counts_t, bins_t = np.histogram(df_test[f'proba_transient'], bins=bins)\n",
    "counts_1, bins_1 = np.histogram(idx_transient, bins=bins)\n",
    "\n",
    "plt.bar(bins[:-1], height=counts_t, width=0.08, align = 'edge')\n",
    "plt.bar(bins[:-1], height=counts_1, width=0.08, align = 'edge')\n",
    "plt.xlabel('Model output : y')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['All data','injected data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ddda35a-5365-4021-9cbb-00bcdf3238b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import umap\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import curdoc\n",
    "\n",
    "class EvaluatingModel:\n",
    "    def __init__(self, model, visit, visual_class=None):\n",
    "        \"\"\"\n",
    "        Initializes the EvaluatingModel class.\n",
    "\n",
    "        Parameters:\n",
    "        model_path (str): Path to the PyTorch model to be evaluated.\n",
    "        visit (int): Visit number for data retrieval.\n",
    "        visual_class (optional): Class for visualizations (if any).\n",
    "        \"\"\"\n",
    "        curdoc().theme = 'dark_minimal'\n",
    "\n",
    "        self.test_size = .99\n",
    "        self.model = model\n",
    "\n",
    "        # Retrieve and prepare data\n",
    "        self.visit = visit\n",
    "        self.data = retrieve_data(nbre_visit=visit, nbre_data=3000)\n",
    "        \n",
    "        # Split data into training and testing sets\n",
    "        self.df_train, df_test, self.x_train, x_test, self.y_train, y_test = self.data.donnees(test_size=self.test_size)\n",
    "        self.df_test_spy, self.x_test, self.y_test = spy(df_test, x_test, y_test)\n",
    "        self.df_test = df_proba_pytorch(self.test_size, self.df_test_spy, self.x_test, self.y_test, model)\n",
    "\n",
    "        # Extract features from the model\n",
    "        self.features_test = self.extract_features(self.x_test)\n",
    "\n",
    "        # Add image data for visualization\n",
    "        self.df_test['image'] = [embeddable_image(data) for data in self.x_test]\n",
    "        \n",
    "        # Apply UMAP for dimensionality reduction on the second-to-last layer\n",
    "        reducer_umapDNN = umap.UMAP(random_state=1)\n",
    "        self.umapDNN_data = reducer_umapDNN.fit_transform(self.features_test)\n",
    "        dim1, dim2 = np.hsplit(self.umapDNN_data, 2)\n",
    "        self.df_test['umapDNN_Dim_1'], self.df_test['umapDNN_Dim_2'] = dim1, dim2\n",
    "        self.df_test_full = self.df_test\n",
    "\n",
    "        # Set plotting parameters\n",
    "        self.width = 800\n",
    "        self.height = 550\n",
    "        self.nbre_pts = 3000\n",
    "        self.data_glob_umap = ColumnDataSource(self.df_test[0:self.nbre_pts])\n",
    "        self.databogus_umap_CNN = ColumnDataSource(self.df_test.loc[self.df_test.bogus_transient == 'bogus'][0:self.nbre_pts])\n",
    "        self.datatransient_umap_CNN = ColumnDataSource(self.df_test.loc[self.df_test.bogus_transient == 'transient'][0:self.nbre_pts])\n",
    "\n",
    "\n",
    "    def extract_features(self, x_test):\n",
    "        \"\"\"\n",
    "        Extract features from the model.\n",
    "\n",
    "        Parameters:\n",
    "        x_test (torch.Tensor): The input data for feature extraction.\n",
    "\n",
    "        Returns:\n",
    "        np.ndarray: The features extracted from the model.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "            features = self.model(x_test_tensor)\n",
    "        return features.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d40a8ef3-0728-4314-85a5-4975800ee731",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_channel=1, n_outputs=1)\n",
    "\n",
    "model_ = model.load_state_dict(torch.load('cnn1_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "825e7dfa-a68d-407c-8e02-8d7f7ea4cb98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluatingModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 30\u001b[0m, in \u001b[0;36mEvaluatingModel.__init__\u001b[0;34m(self, model, visit, visual_class)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_train, df_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, x_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdonnees(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_size)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_test_spy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m spy(df_test, x_test, y_test)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_test \u001b[38;5;241m=\u001b[39m df_proba_pytorch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_test_spy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, \u001b[43mmodel_path\u001b[49m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Extract features from the model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "evaluation = EvaluatingModel(model=model_, visit=visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbee90f-7e77-419b-8d3e-42794d9c740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Data Loader (Input Pipeline)\n",
    "    print('Loading dataset...')\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "    \n",
    "                                              batch_size=batch_size)\n",
    "    # Define models\n",
    "    print('building model...')\n",
    "    cnn1 = CNN(input_channel=input_channel, n_outputs=num_classes)\n",
    "    cnn1.cuda()\n",
    "    print(cnn1.parameters)\n",
    "    optimizer1 = torch.optim.Adam(cnn1.parameters(), lr=learning_rate)\n",
    "    \n",
    "    cnn2 = CNN(input_channel=input_channel, n_outputs=num_classes)\n",
    "    cnn2.cuda()\n",
    "    print(cnn2.parameters)\n",
    "    optimizer2 = torch.optim.Adam(cnn2.parameters(), lr=learning_rate)\n",
    "\n",
    "    mean_pure_ratio1=0\n",
    "    mean_pure_ratio2=0\n",
    "\n",
    "    with open(txtfile, \"a\") as myfile:\n",
    "        myfile.write('epoch: train_acc1 train_acc2 test_acc1 test_acc2 pure_ratio1 pure_ratio2\\n')\n",
    "\n",
    "    epoch=0\n",
    "    train_acc1=0\n",
    "    train_acc2=0\n",
    "    # evaluate models with random weights\n",
    "    test_acc1, test_acc2=evaluate(test_loader, cnn1, cnn2)\n",
    "    print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %% Pure Ratio1 %.4f %% Pure Ratio2 %.4f %%' % (epoch+1, args.n_epoch, len(test_dataset), test_acc1, test_acc2, mean_pure_ratio1, mean_pure_ratio2))\n",
    "    # save results\n",
    "    with open(txtfile, \"a\") as myfile:\n",
    "        myfile.write(str(int(epoch)) + ': '  + str(train_acc1) +' '  + str(train_acc2) +' '  + str(test_acc1) + \" \" + str(test_acc2) + ' '  + str(mean_pure_ratio1) + ' '  + str(mean_pure_ratio2) + \"\\n\")\n",
    "\n",
    "    # training\n",
    "    for epoch in range(1, args.n_epoch):\n",
    "        # train models\n",
    "        cnn1.train()\n",
    "        adjust_learning_rate(optimizer1, epoch)\n",
    "        cnn2.train()\n",
    "        adjust_learning_rate(optimizer2, epoch)\n",
    "        train_acc1, train_acc2, pure_ratio_1_list, pure_ratio_2_list=train(train_loader, epoch, cnn1, optimizer1, cnn2, optimizer2)\n",
    "        # evaluate models\n",
    "        test_acc1, test_acc2=evaluate(test_loader, cnn1, cnn2)\n",
    "        # save results\n",
    "        mean_pure_ratio1 = sum(pure_ratio_1_list)/len(pure_ratio_1_list)\n",
    "        mean_pure_ratio2 = sum(pure_ratio_2_list)/len(pure_ratio_2_list)\n",
    "        print('Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %%, Pure Ratio 1 %.4f %%, Pure Ratio 2 %.4f %%' % (epoch+1, args.n_epoch, len(test_dataset), test_acc1, test_acc2, mean_pure_ratio1, mean_pure_ratio2))\n",
    "        with open(txtfile, \"a\") as myfile:\n",
    "            myfile.write(str(int(epoch)) + ': '  + str(train_acc1) +' '  + str(train_acc2) +' '  + str(test_acc1) + \" \" + str(test_acc2) + ' ' + str(mean_pure_ratio1) + ' ' + str(mean_pure_ratio2) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4transients_env",
   "language": "python",
   "name": "ml4transients_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
